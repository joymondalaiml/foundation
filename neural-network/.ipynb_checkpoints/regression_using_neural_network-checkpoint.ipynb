{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83af0bb",
   "metadata": {},
   "source": [
    "## References\n",
    "- Machine Learning with Python Cookbook, 2nd Edition, Kyle Gallatin, Chris Albon, O'Reilly Media, Inc.\n",
    "- http://alexlenail.me/NN-SVG/index.html\n",
    "- https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82c162b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all the necessary libraries at the beginning\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop \n",
    "from sklearn.datasets import make_regression \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "601c675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "Using device: cuda\n",
      "\n",
      "True\n",
      "1\n",
      "<torch.cuda.device object at 0x00000276264AA520>\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "# Additional Info when using CUDA\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.is_available())\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.device(0))\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b3415",
   "metadata": {},
   "source": [
    "### What is CUDA?\n",
    "CUDA is a programming model and computing toolkit developed by NVIDIA. It enables you to perform compute-intensive operations faster by parallelizing tasks across GPUs. CUDA is the dominant API used for deep learning although other options are available, such as OpenCL. PyTorch provides support for CUDA in the torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97e6083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate a sample regression dataset\n",
    "features, target = make_regression(n_features = 5, n_samples = 1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51065422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature set -> type - <class 'numpy.ndarray'>, shape - (900, 5)\n",
      "[-0.94676239 -1.215222    0.01770675  0.37488315  0.56145877]\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the dataset\n",
    "print('Training feature set -> type - {}, shape - {}'.format(type(features_train), features_train.shape))\n",
    "print(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2452f894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test feature set -> type - <class 'numpy.ndarray'>, shape - (100, 5)\n",
      "[ 0.71654831 -1.62444604 -0.42186141  1.59541193 -2.00873225]\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the dataset\n",
    "print('Test feature set -> type - {}, shape - {}'.format(type(features_test), features_test.shape))\n",
    "print(features_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5eec703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target set -> type - <class 'numpy.ndarray'>, shape - (900,)\n",
      "-138.52135262757946\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the dataset\n",
    "print('Training target set -> type - {}, shape - {}'.format(type(target_train), target_train.shape))\n",
    "print(target_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33e2a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test target set -> type - <class 'numpy.ndarray'>, shape - (100,)\n",
      "-15.527435215048516\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the dataset\n",
    "print('Test target set -> type - {}, shape - {}'.format(type(target_test), target_test.shape))\n",
    "print(target_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc5acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with Pytorch, we need to convert the ndarrays to tensors\n",
    "x_train = torch.from_numpy(features_train).float() \n",
    "y_train = torch.from_numpy(target_train).float().view(-1,1) \n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805e52a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature set -> type - <class 'torch.Tensor'>, shape - torch.Size([900, 5]), is CUDA - False\n",
      "tensor([-0.9468, -1.2152,  0.0177,  0.3749,  0.5615])\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the converted dataset\n",
    "print('Training feature set -> type - {}, shape - {}, is CUDA - {}'.format(type(x_train), x_train.shape, x_train.is_cuda))\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "513706db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test feature set -> type - <class 'torch.Tensor'>, shape - torch.Size([100, 5]), is CUDA - False\n",
      "tensor([ 0.7165, -1.6244, -0.4219,  1.5954, -2.0087])\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the converted dataset\n",
    "print('Test feature set -> type - {}, shape - {}, is CUDA - {}'.format(type(x_test), x_test.shape, x_test.is_cuda))\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8ffc157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target set -> type - <class 'torch.Tensor'>, shape - torch.Size([900, 1]), is CUDA - False\n",
      "tensor([-138.5213])\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the converted dataset\n",
    "print('Train target set -> type - {}, shape - {}, is CUDA - {}'.format(type(y_train), y_train.shape, y_train.is_cuda))\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e861f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test target set -> type - <class 'torch.Tensor'>, shape - torch.Size([100, 1]), is CUDA - False\n",
      "tensor([-15.5274])\n"
     ]
    }
   ],
   "source": [
    "# Print the type and shape of the converted dataset\n",
    "print('Test target set -> type - {}, shape - {}, is CUDA - {}'.format(type(y_test), y_test.shape, y_test.is_cuda))\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a6e61b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test target set -> type - <class 'torch.Tensor'>, shape - torch.Size([100, 1]), is CUDA - True\n",
      "tensor([-15.5274], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Now, send all the datasets to GPU, if available\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# Print the type and shape of the converted dataset\n",
    "print('Test target set -> type - {}, shape - {}, is CUDA - {}'.format(type(y_test), y_test.shape, y_test.is_cuda))\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e15884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Netowrk to solve this regression problem\n",
    "class RegressorNeuralNet(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(RegressorNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 10) # in_features=5, out_features=10\n",
    "        self.fc2 = nn.Linear(10, 10) # in_features=10, out_features=10\n",
    "        self.fc3 = nn.Linear(10, 1)  # in_features=10, out_features=1\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = nn.functional.relu(self.fc1(x))    # We used RELU as the activation function\n",
    "        x = nn.functional.relu(self.fc2(x))    # We used RELU as the activation function\n",
    "        x = self.fc3(x)                        # No activation function at the output layer as this is a regression problem\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bff69",
   "metadata": {},
   "source": [
    "### Activation function\n",
    "- The purpose of an activation function is to introduce **non-linearity** into the output of a neuron.\n",
    "- Following are few popular activation functions for hidden layers:\n",
    "    - Rectified linear activation function or RELU\n",
    "    - Sigmoid\n",
    "    - TanH\n",
    "- Following are few popular activation functions for output layers:\n",
    "    - Linear\n",
    "    - Sigmoid\n",
    "    - Softmax\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "      <td>\n",
    "      <img src='Linear.png' width=300>\n",
    "      </td>\n",
    "      <td>\n",
    "      <img src='RELU.png' width=300>\n",
    "      </td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "      <td>\n",
    "      Linear\n",
    "      </td>\n",
    "      <td>\n",
    "      RELU\n",
    "      </td>\n",
    "     </tr>  \n",
    "    <tr>\n",
    "      <td>\n",
    "      <img src='Sigmoid.png' width=300>\n",
    "      </td>\n",
    "      <td>\n",
    "      <img src='TanH.png' width=300>\n",
    "      </td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "      <td>\n",
    "      Sigmoid\n",
    "      </td>\n",
    "      <td>\n",
    "      TanH\n",
    "      </td>\n",
    "     </tr>     \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b1f3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network now\n",
    "network = RegressorNeuralNet()\n",
    "\n",
    "# Define loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = RMSprop(network.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b826da",
   "metadata": {},
   "source": [
    "## Calculating loss for regression problems\n",
    "### We need to know how close are the predictions of the network to the actual targets\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error, this is in the square of the target value, so not very intuititive\n",
    "- Root Mean Squared Error, this is in the same unit as the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad97e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressorNeuralNet(\n",
       "  (fc1): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the network\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027d834",
   "metadata": {},
   "source": [
    "<img src=\"regressor_neural_network.png\" align=\"left\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6b7c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressorNeuralNet(\n",
       "  (fc1): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the network to GPU as well, if available\n",
    "network.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4671f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define the dataloader\n",
    "train_data = TensorDataset(x_train, y_train) \n",
    "train_loader = DataLoader(train_data, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "484ead86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of EPOCHS we want to train\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82ad058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tLoss: 19860.64453125\n",
      "Epoch: 2 \tLoss: 7681.814453125\n",
      "Epoch: 3 \tLoss: 3047.110595703125\n",
      "Epoch: 4 \tLoss: 3448.823974609375\n",
      "Epoch: 5 \tLoss: 1567.0345458984375\n",
      "Epoch: 6 \tLoss: 659.45068359375\n",
      "Epoch: 7 \tLoss: 664.176513671875\n",
      "Epoch: 8 \tLoss: 405.0368347167969\n",
      "Epoch: 9 \tLoss: 316.1385192871094\n",
      "Epoch: 10 \tLoss: 363.69683837890625\n",
      "Epoch: 11 \tLoss: 296.521484375\n",
      "Epoch: 12 \tLoss: 216.78538513183594\n",
      "Epoch: 13 \tLoss: 205.28973388671875\n",
      "Epoch: 14 \tLoss: 282.2417907714844\n",
      "Epoch: 15 \tLoss: 176.0799560546875\n",
      "Epoch: 16 \tLoss: 181.28224182128906\n",
      "Epoch: 17 \tLoss: 204.53782653808594\n",
      "Epoch: 18 \tLoss: 184.54037475585938\n",
      "Epoch: 19 \tLoss: 184.8148651123047\n",
      "Epoch: 20 \tLoss: 134.3917999267578\n"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        optimizer.zero_grad()  # This is very important to zero out the gradient before every iterations\n",
    "        output = network(data) # This is where we are performing the forward propagation\n",
    "        loss = criterion(output, target) # This is where we are calculating the loss\n",
    "        loss.backward() # This is where we are performing the backward propagation\n",
    "        optimizer.step() # This is where we update the network parameters\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b97a0287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 188.34962463378906\n"
     ]
    }
   ],
   "source": [
    "# Evaluate neural network \n",
    "with torch.no_grad(): # When we evaluate the network, we dont track the gradients\n",
    "    output = network(x_test) # We derive the output\n",
    "    test_loss = float(criterion(output, y_test)) # We calculate the loss\n",
    "    print(\"Test MSE:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7907ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
